{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP02wtM0O3MfLg6f2n6MNps",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SolarMeIster/Math_linguistics/blob/main/Lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBnqY6J-CUMl",
        "outputId": "1b4e9ae2-a03d-41b0-cd5e-2c1117256b4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymorphy3 in /usr/local/lib/python3.11/dist-packages (2.0.3)\n",
            "Requirement already satisfied: dawg2-python>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from pymorphy3) (0.9.0)\n",
            "Requirement already satisfied: pymorphy3-dicts-ru in /usr/local/lib/python3.11/dist-packages (from pymorphy3) (2.4.417150.4580142)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymorphy3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from pymorphy3 import MorphAnalyzer\n",
        "from collections import Counter\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRAS9x8wDRsN",
        "outputId": "e0b5a57a-f99e-4c32-c439-b41978aa0587"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "В тексте посчитать количество различных слов, для чего потребуется\n",
        "выполнить токенизацию по словам любым способом. Далее использовать\n",
        "готовый стеммер и лемматизатор из любой библиотеки.\n",
        "Произвести удаление стоп-слов из текста.\n",
        "Посчитать количество различных слов в тесте до и после каждого\n",
        "процесса, а также всех их комбинаций.\n",
        "Субъективно оценить понятность текста после стемминга, лемматизации\n",
        "и удаления стоп-слов.\n",
        "Написать код для векторизации текста, используя различный размер\n",
        "словаря, который выводит результат векторизации, а также производит\n",
        "обратный процесс — заменяет все численные значения, которые есть в\n",
        "словаре, на слова.\n",
        "Оценить понятность текста, прошедшего векторизацию и обратное\n",
        "преобразование, если перед векторизацией выполнялись или не выполнялись\n",
        "стемминг, лемматизация и удаление стоп-слов. Определить оптимальную\n",
        "комбинацию для вашего текста.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "yjljj55TDXBn"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def words_freq(words):\n",
        "  words_counts = Counter(words)\n",
        "  df = pd.DataFrame(words_counts.items(), columns=[\"Слово\", \"Частота\"])\n",
        "  print(df)"
      ],
      "metadata": {
        "id": "JtpRuzT8QDsm"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Токенизация слов"
      ],
      "metadata": {
        "id": "MXgzDwdPHFE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(text.lower(), language='russian')\n",
        "unique_words = set(words)\n",
        "\n",
        "print(f\"Количество слов до обработки: {len(words)}\")\n",
        "print(f\"Количество различных слов до обработки: {len(unique_words)}\")\n",
        "words_freq(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ3rMabzDi-C",
        "outputId": "8087c41b-8d74-4578-bf9c-6136c7a8aa33"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество слов до обработки: 129\n",
            "Количество различных слов до обработки: 85\n",
            "           Слово  Частота\n",
            "0              в        3\n",
            "1         тексте        1\n",
            "2      посчитать        2\n",
            "3     количество        2\n",
            "4      различных        2\n",
            "..           ...      ...\n",
            "80  лемматизация        1\n",
            "81    определить        1\n",
            "82   оптимальную        1\n",
            "83    комбинацию        1\n",
            "84        вашего        1\n",
            "\n",
            "[85 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Стеминг слов"
      ],
      "metadata": {
        "id": "OIbRN7FkHOlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = SnowballStemmer(\"russian\")\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "unique_stemmed_words = set(stemmed_words)\n",
        "\n",
        "print(f\"Количество слов после стемминга: {len(stemmed_words)}\")\n",
        "print(f\"Количество различных слов после стемминга: {len(unique_stemmed_words)}\")\n",
        "words_freq(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZjhyKPpDkvP",
        "outputId": "22b04578-2426-496d-a192-f87c6c4b0cc3"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество слов после стемминга: 129\n",
            "Количество различных слов после стемминга: 70\n",
            "        Слово  Частота\n",
            "0           в        3\n",
            "1       текст        6\n",
            "2     посчита        2\n",
            "3   количеств        2\n",
            "4     различн        3\n",
            "..        ...      ...\n",
            "65         ил        1\n",
            "66         не        1\n",
            "67    определ        1\n",
            "68  оптимальн        1\n",
            "69        ваш        1\n",
            "\n",
            "[70 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Лематизация слов"
      ],
      "metadata": {
        "id": "t8ZSV5PdHWI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "morph = MorphAnalyzer()\n",
        "lemmatized_words = [morph.parse(word)[0].normal_form for word in words]\n",
        "unique_lemmatized_words = set(lemmatized_words)\n",
        "\n",
        "print(f\"Количество слов после лемматизации: {len(lemmatized_words)}\")\n",
        "print(f\"Количество различных слов после лемматизации: {len(unique_lemmatized_words)}\")\n",
        "words_freq(lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8tdMLiVDlto",
        "outputId": "939a1389-d6e1-4358-df4a-0a0ffd2ce227"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество слов после лемматизации: 129\n",
            "Количество различных слов после лемматизации: 69\n",
            "          Слово  Частота\n",
            "0             в        3\n",
            "1         текст        6\n",
            "2     посчитать        2\n",
            "3    количество        2\n",
            "4     различный        3\n",
            "..          ...      ...\n",
            "64          или        1\n",
            "65           не        1\n",
            "66   определить        1\n",
            "67  оптимальный        1\n",
            "68          ваш        1\n",
            "\n",
            "[69 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Удаление стоп-слов"
      ],
      "metadata": {
        "id": "w9sF0JtFHatu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('russian'))\n",
        "filtered_words = [word for word in words if word not in stop_words]\n",
        "unique_filtered_words = set(filtered_words)\n",
        "\n",
        "print(f\"Количество слов после удаления стоп-слов: {len(filtered_words)}\")\n",
        "print(f\"Количество различных слов после удаления стоп-слов: {len(unique_filtered_words)}\")\n",
        "words_freq(filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQI6WI_mDmt6",
        "outputId": "870d7b2c-8367-4ba1-e110-434196c8e7f0"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество слов после удаления стоп-слов: 100\n",
            "Количество различных слов после удаления стоп-слов: 67\n",
            "           Слово  Частота\n",
            "0         тексте        1\n",
            "1      посчитать        2\n",
            "2     количество        2\n",
            "3      различных        2\n",
            "4           слов        2\n",
            "..           ...      ...\n",
            "62  лемматизация        1\n",
            "63    определить        1\n",
            "64   оптимальную        1\n",
            "65    комбинацию        1\n",
            "66        вашего        1\n",
            "\n",
            "[67 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Комбинации методов"
      ],
      "metadata": {
        "id": "CdgTbP_-PghA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Стемминг + удаление стоп-слов\n",
        "stemmed_filtered_words = [stemmer.stem(word) for word in filtered_words]\n",
        "unique_stemmed_filtered_words = set(stemmed_filtered_words)\n",
        "\n",
        "print(f\"Количество слов после стемминга и удаления стоп-слов: {len(stemmed_filtered_words)}\")\n",
        "print(f\"Количество различных слов после стемминга и удаления стоп-слов: {len(unique_stemmed_filtered_words)}\")\n",
        "words_freq(stemmed_filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0voJEFSWfex",
        "outputId": "c6ad6f7e-e634-481e-ef80-2f71f56de348"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество слов после стемминга и удаления стоп-слов: 100\n",
            "Количество различных слов после стемминга и удаления стоп-слов: 52\n",
            "           Слово  Частота\n",
            "0          текст        6\n",
            "1        посчита        2\n",
            "2      количеств        2\n",
            "3        различн        3\n",
            "4           слов        4\n",
            "5              ,       11\n",
            "6         потреб        1\n",
            "7         выполн        1\n",
            "8      токенизац        1\n",
            "9            люб        2\n",
            "10        способ        1\n",
            "11             .        8\n",
            "12           дал        1\n",
            "13    использова        1\n",
            "14         готов        1\n",
            "15       стеммер        1\n",
            "16  лемматизатор        1\n",
            "17     библиотек        1\n",
            "18     произвест        1\n",
            "19        удален        3\n",
            "20       стоп-сл        3\n",
            "21          тест        1\n",
            "22          кажд        1\n",
            "23       процесс        2\n",
            "24          такж        2\n",
            "25      комбинац        2\n",
            "26    субъективн        1\n",
            "27          оцен        2\n",
            "28        понятн        2\n",
            "29      стемминг        2\n",
            "30    лемматизац        2\n",
            "31        написа        1\n",
            "32           код        1\n",
            "33    векторизац        4\n",
            "34      использу        1\n",
            "35        размер        1\n",
            "36        словар        2\n",
            "37         котор        2\n",
            "38         вывод        1\n",
            "39     результат        1\n",
            "40      производ        1\n",
            "41        обратн        2\n",
            "42             —        1\n",
            "43        заменя        1\n",
            "44        числен        1\n",
            "45        значен        1\n",
            "46       прошедш        1\n",
            "47  преобразован        1\n",
            "48       выполня        2\n",
            "49       определ        1\n",
            "50     оптимальн        1\n",
            "51           ваш        1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Лемматизация + удаление стоп-слов\n",
        "lemmatized_filtered_words = [morph.parse(word)[0].normal_form for word in filtered_words]\n",
        "unique_lemmatized_filtered_words = set(lemmatized_filtered_words)\n",
        "\n",
        "print(f\"Количество слов после лемматизации и удаления стоп-слов: {len(lemmatized_filtered_words)}\")\n",
        "print(f\"Количество различных слов после лемматизации и удаления стоп-слов: {len(unique_lemmatized_filtered_words)}\")\n",
        "words_freq(lemmatized_filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsEnco6MPgEY",
        "outputId": "34493431-b90d-4ed2-bb2b-f8af785770fc"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество слов после лемматизации и удаления стоп-слов: 100\n",
            "Количество различных слов после лемматизации и удаления стоп-слов: 51\n",
            "             Слово  Частота\n",
            "0            текст        6\n",
            "1        посчитать        2\n",
            "2       количество        2\n",
            "3        различный        3\n",
            "4            слово        4\n",
            "5                ,       11\n",
            "6    потребоваться        1\n",
            "7        выполнить        1\n",
            "8      токенизация        1\n",
            "9            любой        2\n",
            "10          способ        1\n",
            "11               .        8\n",
            "12           далее        1\n",
            "13    использовать        2\n",
            "14         готовый        1\n",
            "15        стеммера        1\n",
            "16    лемматизатор        1\n",
            "17      библиотека        1\n",
            "18      произвести        1\n",
            "19        удаление        3\n",
            "20     стопа-слово        3\n",
            "21            тест        1\n",
            "22          каждый        1\n",
            "23         процесс        2\n",
            "24           также        2\n",
            "25      комбинация        2\n",
            "26     субъективно        1\n",
            "27         оценить        2\n",
            "28      понятность        2\n",
            "29        стемминг        2\n",
            "30    лемматизация        2\n",
            "31        написать        1\n",
            "32             код        1\n",
            "33    векторизация        4\n",
            "34          размер        1\n",
            "35         словарь        2\n",
            "36         который        2\n",
            "37        выводить        1\n",
            "38       результат        1\n",
            "39     производить        1\n",
            "40        обратный        2\n",
            "41               —        1\n",
            "42        заменять        1\n",
            "43       численный        1\n",
            "44        значение        1\n",
            "45       прошедшее        1\n",
            "46  преобразование        1\n",
            "47     выполняться        2\n",
            "48      определить        1\n",
            "49     оптимальный        1\n",
            "50             ваш        1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_text = ' '.join(lemmatized_words)\n",
        "stemmed_text = ' '.join(stemmed_words)\n",
        "filtered_text = ' '.join(filtered_words)"
      ],
      "metadata": {
        "id": "Eb8OLHRzTyXR"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Векторизация слов"
      ],
      "metadata": {
        "id": "PJgIHA5SHfDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_text(text, vocab_size):\n",
        "    vectorizer = CountVectorizer(max_features=vocab_size)\n",
        "    X = vectorizer.fit_transform([text])\n",
        "    return X, vectorizer\n",
        "\n",
        "def inverse_transform(X, vectorizer):\n",
        "    return vectorizer.inverse_transform(X)"
      ],
      "metadata": {
        "id": "WGIL2Ba7Dr9o"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# векторизации лематизированных слов\n",
        "X, vectorizer = vectorize_text(lemmatized_text, 50)\n",
        "print(\"Результат векторизации:\")\n",
        "print(X.toarray())\n",
        "\n",
        "inverse_text = inverse_transform(X, vectorizer)\n",
        "print(\"Обратное преобразование:\")\n",
        "print(inverse_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efLgyC9OUJ5m",
        "outputId": "ce98d32b-a33e-444e-81f1-176b02271a02"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат векторизации:\n",
            "[[1 1 4 1 1 1 1 2 1 1 3 1 1 1 2 2 2 2 2 2 2 2 1 2 1 1 2 2 2 1 1 1 1 2 1 3\n",
            "  1 1 2 7 1 1 2 3 1 2 6 1 1 3]]\n",
            "Обратное преобразование:\n",
            "[array(['текст', 'посчитать', 'количество', 'различный', 'слово', 'для',\n",
            "       'потребоваться', 'выполнить', 'токенизация', 'по', 'любой',\n",
            "       'способ', 'далее', 'использовать', 'готовый', 'стеммера', 'из',\n",
            "       'библиотека', 'произвести', 'удаление', 'стопа', 'тест', 'до',\n",
            "       'после', 'процесс', 'также', 'весь', 'они', 'комбинация',\n",
            "       'субъективно', 'оценить', 'понятность', 'стемминг', 'лемматизация',\n",
            "       'векторизация', 'размер', 'словарь', 'который', 'выводить',\n",
            "       'результат', 'производить', 'обратный', 'всё', 'есть', 'прошедшее',\n",
            "       'преобразование', 'если', 'перед', 'выполняться', 'ваш'],\n",
            "      dtype='<U14')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# векторизации стемминговых слов\n",
        "X, vectorizer = vectorize_text(stemmed_text, 50)\n",
        "print(\"Результат векторизации:\")\n",
        "print(X.toarray())\n",
        "\n",
        "inverse_text = inverse_transform(X, vectorizer)\n",
        "print(\"Обратное преобразование:\")\n",
        "print(inverse_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxdKpR6tVM_3",
        "outputId": "a2fd9865-4e4c-408c-fd91-d7a36c5f9603"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат векторизации:\n",
            "[[1 1 4 1 1 1 1 2 1 1 3 1 1 1 1 2 2 2 2 2 2 2 1 2 1 2 2 2 1 1 1 1 2 1 3 1\n",
            "  1 3 4 2 1 1 2 3 1 2 6 1 1 3]]\n",
            "Обратное преобразование:\n",
            "[array(['текст', 'посчита', 'количеств', 'различн', 'слов', 'для',\n",
            "       'потреб', 'выполн', 'токенизац', 'по', 'люб', 'способ', 'дал',\n",
            "       'готов', 'стеммер', 'из', 'библиотек', 'произвест', 'удален',\n",
            "       'стоп', 'сл', 'тест', 'до', 'посл', 'процесс', 'такж', 'всех',\n",
            "       'комбинац', 'субъективн', 'оцен', 'понятн', 'стемминг',\n",
            "       'лемматизац', 'векторизац', 'размер', 'словар', 'котор', 'вывод',\n",
            "       'результат', 'производ', 'обратн', 'заменя', 'все', 'ест',\n",
            "       'прошедш', 'преобразован', 'есл', 'выполня', 'оптимальн', 'ваш'],\n",
            "      dtype='<U12')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# векторизации отфильтрованных слов (после удаления стоп-слов)\n",
        "X, vectorizer = vectorize_text(filtered_text, 50)\n",
        "print(\"Результат векторизации:\")\n",
        "print(X.toarray())\n",
        "\n",
        "inverse_text = inverse_transform(X, vectorizer)\n",
        "print(\"Обратное преобразование:\")\n",
        "print(inverse_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui9n0Ae-VMh4",
        "outputId": "02431e68-37db-4e3c-8637-93460b686217"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат векторизации:\n",
            "[[1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 2 1 2 2 2 1 1 1 1 1 1 1 1 2 1 1 5 1 1 1\n",
            "  1 1 1 1 1 3 1 2 5 1 1 1 2 1]]\n",
            "Обратное преобразование:\n",
            "[array(['тексте', 'посчитать', 'количество', 'различных', 'слов',\n",
            "       'потребуется', 'выполнить', 'токенизацию', 'словам', 'способом',\n",
            "       'далее', 'использовать', 'готовый', 'стеммер', 'библиотеки',\n",
            "       'произвести', 'удаление', 'стоп', 'текста', 'тесте', 'каждого',\n",
            "       'процесса', 'также', 'субъективно', 'оценить', 'понятность',\n",
            "       'стемминга', 'удаления', 'код', 'векторизации', 'используя',\n",
            "       'различный', 'размер', 'словаря', 'выводит', 'результат',\n",
            "       'производит', 'процесс', 'заменяет', 'значения', 'словаре',\n",
            "       'слова', 'прошедшего', 'векторизацию', 'преобразование',\n",
            "       'векторизацией', 'выполнялись', 'стемминг', 'оптимальную',\n",
            "       'вашего'], dtype='<U14')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Оценка методов работы с текстом"
      ],
      "metadata": {
        "id": "6OVLAivTHi2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_text_understandability(text):\n",
        "    # Субъективная оценка понятности текста\n",
        "    print(f\"Текст: {text}\")\n",
        "    understandability = input(\"Оцените понятность текста (1-10): \")\n",
        "    return int(understandability)\n",
        "\n",
        "# Оценка понятности после стемминга\n",
        "print(\"Оценка понятности после стемминга:\")\n",
        "stemmed_score = evaluate_text_understandability(stemmed_text)\n",
        "\n",
        "# Оценка понятности после лемматизации\n",
        "print(\"Оценка понятности после лемматизации:\")\n",
        "lemmatized_score = evaluate_text_understandability(lemmatized_text)\n",
        "\n",
        "# Оценка понятности после удаления стоп-слов\n",
        "print(\"Оценка понятности после удаления стоп-слов:\")\n",
        "filtered_score = evaluate_text_understandability(filtered_text)\n",
        "\n",
        "# Оценка понятности после векторизации и обратного преобразования\n",
        "inverse_text_str = ' '.join([' '.join(words) for words in inverse_text])\n",
        "print(\"Оценка понятности после векторизации и обратного преобразования:\")\n",
        "inverse_score = evaluate_text_understandability(inverse_text_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "Iemnv9j-DuGg",
        "outputId": "ca665210-48b3-49fc-cf27-329159f36989"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Оценка понятности после стемминга:\n",
            "Текст: в текст посчита количеств различн слов , для чег потреб выполн токенизац по слов люб способ . дал использова готов стеммер и лемматизатор из люб библиотек . произвест удален стоп-сл из текст . посчита количеств различн слов в тест до и посл кажд процесс , а такж всех их комбинац . субъективн оцен понятн текст посл стемминг , лемматизац и удален стоп-сл . написа код для векторизац текст , использу различн размер словар , котор вывод результат векторизац , а такж производ обратн процесс — заменя все числен значен , котор ест в словар , на слов . оцен понятн текст , прошедш векторизац и обратн преобразован , есл перед векторизац выполня ил не выполня стемминг , лемматизац и удален стоп-сл . определ оптимальн комбинац для ваш текст .\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-135-81689ba75026>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Оценка понятности после стемминга\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Оценка понятности после стемминга:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mstemmed_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_text_understandability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstemmed_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Оценка понятности после лемматизации\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-135-81689ba75026>\u001b[0m in \u001b[0;36mevaluate_text_understandability\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Субъективная оценка понятности текста\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Текст: {text}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0munderstandability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Оцените понятность текста (1-10): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munderstandability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вывод оптимального метода"
      ],
      "metadata": {
        "id": "DQTFKhatHpPi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "49TUjsolWH59"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}