{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOt0Yl5TtfLvebNC3iDRd9T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SolarMeIster/Math_linguistics/blob/main/Lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBnqY6J-CUMl",
        "outputId": "913ec697-d529-469f-8a44-6e811be4af40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy3\n",
            "  Downloading pymorphy3-2.0.3-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting dawg2-python>=0.8.0 (from pymorphy3)\n",
            "  Downloading dawg2_python-0.9.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting pymorphy3-dicts-ru (from pymorphy3)\n",
            "  Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Downloading pymorphy3-2.0.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dawg2_python-0.9.0-py3-none-any.whl (9.3 kB)\n",
            "Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymorphy3-dicts-ru, dawg2-python, pymorphy3\n",
            "Successfully installed dawg2-python-0.9.0 pymorphy3-2.0.3 pymorphy3-dicts-ru-2.4.417150.4580142\n"
          ]
        }
      ],
      "source": [
        "!pip install pymorphy3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from pymorphy3 import MorphAnalyzer\n",
        "from collections import Counter\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRAS9x8wDRsN",
        "outputId": "0e197a57-95bd-49a7-cb51-e102bd3d7d77"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "В тексте посчитать количество различных слов, для чего потребуется\n",
        "выполнить токенизацию по словам любым способом. Далее использовать\n",
        "готовый стеммер и лемматизатор из любой библиотеки.\n",
        "Произвести удаление стоп-слов из текста.\n",
        "Посчитать количество различных слов в тесте до и после каждого\n",
        "процесса, а также всех их комбинаций.\n",
        "Субъективно оценить понятность текста после стемминга, лемматизации\n",
        "и удаления стоп-слов.\n",
        "Написать код для векторизации текста, используя различный размер\n",
        "словаря, который выводит результат векторизации, а также производит\n",
        "обратный процесс — заменяет все численные значения, которые есть в\n",
        "словаре, на слова.\n",
        "Оценить понятность текста, прошедшего векторизацию и обратное\n",
        "преобразование, если перед векторизацией выполнялись или не выполнялись\n",
        "стемминг, лемматизация и удаление стоп-слов. Определить оптимальную\n",
        "комбинацию для вашего текста.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "yjljj55TDXBn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def words_freq(words):\n",
        "  words_counts = Counter(words)\n",
        "  df = pd.DataFrame(words_counts.items(), columns=[\"Слово\", \"Частота\"])\n",
        "  print(df)"
      ],
      "metadata": {
        "id": "JtpRuzT8QDsm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Токенизация слов"
      ],
      "metadata": {
        "id": "MXgzDwdPHFE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(text.lower(), language='russian')\n",
        "unique_words = set(words)\n",
        "\n",
        "print(f\"Количество слов до обработки: {len(words)}\")\n",
        "print(f\"Количество различных слов до обработки: {len(unique_words)}\")\n",
        "words_freq(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ3rMabzDi-C",
        "outputId": "9d06f12f-c04d-44cf-c7b7-018173ba14c1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество слов до обработки: 129\n",
            "Количество различных слов до обработки: 85\n",
            "           Слово  Частота\n",
            "0              в        3\n",
            "1         тексте        1\n",
            "2      посчитать        2\n",
            "3     количество        2\n",
            "4      различных        2\n",
            "..           ...      ...\n",
            "80  лемматизация        1\n",
            "81    определить        1\n",
            "82   оптимальную        1\n",
            "83    комбинацию        1\n",
            "84        вашего        1\n",
            "\n",
            "[85 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Стеминг слов"
      ],
      "metadata": {
        "id": "OIbRN7FkHOlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = SnowballStemmer(\"russian\")\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "unique_stemmed_words = set(stemmed_words)\n",
        "\n",
        "print(f\"Количество слов после стемминга: {len(stemmed_words)}\")\n",
        "print(f\"Количество различных слов после стемминга: {len(unique_stemmed_words)}\")\n",
        "words_freq(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZjhyKPpDkvP",
        "outputId": "54e32641-9f71-47f2-fdb5-81b421529cae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество слов после стемминга: 129\n",
            "Количество различных слов после стемминга: 70\n",
            "        Слово  Частота\n",
            "0           в        3\n",
            "1       текст        6\n",
            "2     посчита        2\n",
            "3   количеств        2\n",
            "4     различн        3\n",
            "..        ...      ...\n",
            "65         ил        1\n",
            "66         не        1\n",
            "67    определ        1\n",
            "68  оптимальн        1\n",
            "69        ваш        1\n",
            "\n",
            "[70 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Лематизация слов"
      ],
      "metadata": {
        "id": "t8ZSV5PdHWI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "morph = MorphAnalyzer()\n",
        "lemmatized_words = [morph.parse(word)[0].normal_form for word in words]\n",
        "unique_lemmatized_words = set(lemmatized_words)\n",
        "\n",
        "print(f\"Количество слов после лемматизации: {len(lemmatized_words)}\")\n",
        "print(f\"Количество различных слов после лемматизации: {len(unique_lemmatized_words)}\")\n",
        "words_freq(lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8tdMLiVDlto",
        "outputId": "802a9780-d242-4992-8059-76761c88fb95"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество слов после лемматизации: 129\n",
            "Количество различных слов после лемматизации: 69\n",
            "          Слово  Частота\n",
            "0             в        3\n",
            "1         текст        6\n",
            "2     посчитать        2\n",
            "3    количество        2\n",
            "4     различный        3\n",
            "..          ...      ...\n",
            "64          или        1\n",
            "65           не        1\n",
            "66   определить        1\n",
            "67  оптимальный        1\n",
            "68          ваш        1\n",
            "\n",
            "[69 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Удаление стоп-слов"
      ],
      "metadata": {
        "id": "w9sF0JtFHatu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('russian'))\n",
        "filtered_words = [word for word in words if word not in stop_words]\n",
        "unique_filtered_words = set(filtered_words)\n",
        "\n",
        "print(f\"Количество слов после удаления стоп-слов: {len(filtered_words)}\")\n",
        "print(f\"Количество различных слов после удаления стоп-слов: {len(unique_filtered_words)}\")\n",
        "words_freq(filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQI6WI_mDmt6",
        "outputId": "cbb73b31-aabd-4cf0-ed72-caa397df1e78"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество слов после удаления стоп-слов: 100\n",
            "Количество различных слов после удаления стоп-слов: 67\n",
            "           Слово  Частота\n",
            "0         тексте        1\n",
            "1      посчитать        2\n",
            "2     количество        2\n",
            "3      различных        2\n",
            "4           слов        2\n",
            "..           ...      ...\n",
            "62  лемматизация        1\n",
            "63    определить        1\n",
            "64   оптимальную        1\n",
            "65    комбинацию        1\n",
            "66        вашего        1\n",
            "\n",
            "[67 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Комбинации методов"
      ],
      "metadata": {
        "id": "CdgTbP_-PghA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmed_filtered_words = [stemmer.stem(word) for word in filtered_words]\n",
        "unique_stemmed_filtered_words = set(stemmed_filtered_words)\n",
        "\n",
        "print(f\"Количество слов после стемминга и удаления стоп-слов: {len(stemmed_filtered_words)}\")\n",
        "print(f\"Количество различных слов после стемминга и удаления стоп-слов: {len(unique_stemmed_filtered_words)}\")\n",
        "words_freq(stemmed_filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0voJEFSWfex",
        "outputId": "5b81f7e5-5e48-4765-8e43-29d4b8d31648"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество слов после стемминга и удаления стоп-слов: 100\n",
            "Количество различных слов после стемминга и удаления стоп-слов: 52\n",
            "           Слово  Частота\n",
            "0          текст        6\n",
            "1        посчита        2\n",
            "2      количеств        2\n",
            "3        различн        3\n",
            "4           слов        4\n",
            "5              ,       11\n",
            "6         потреб        1\n",
            "7         выполн        1\n",
            "8      токенизац        1\n",
            "9            люб        2\n",
            "10        способ        1\n",
            "11             .        8\n",
            "12           дал        1\n",
            "13    использова        1\n",
            "14         готов        1\n",
            "15       стеммер        1\n",
            "16  лемматизатор        1\n",
            "17     библиотек        1\n",
            "18     произвест        1\n",
            "19        удален        3\n",
            "20       стоп-сл        3\n",
            "21          тест        1\n",
            "22          кажд        1\n",
            "23       процесс        2\n",
            "24          такж        2\n",
            "25      комбинац        2\n",
            "26    субъективн        1\n",
            "27          оцен        2\n",
            "28        понятн        2\n",
            "29      стемминг        2\n",
            "30    лемматизац        2\n",
            "31        написа        1\n",
            "32           код        1\n",
            "33    векторизац        4\n",
            "34      использу        1\n",
            "35        размер        1\n",
            "36        словар        2\n",
            "37         котор        2\n",
            "38         вывод        1\n",
            "39     результат        1\n",
            "40      производ        1\n",
            "41        обратн        2\n",
            "42             —        1\n",
            "43        заменя        1\n",
            "44        числен        1\n",
            "45        значен        1\n",
            "46       прошедш        1\n",
            "47  преобразован        1\n",
            "48       выполня        2\n",
            "49       определ        1\n",
            "50     оптимальн        1\n",
            "51           ваш        1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_filtered_words = [morph.parse(word)[0].normal_form for word in filtered_words]\n",
        "unique_lemmatized_filtered_words = set(lemmatized_filtered_words)\n",
        "\n",
        "print(f\"Количество слов после лемматизации и удаления стоп-слов: {len(lemmatized_filtered_words)}\")\n",
        "print(f\"Количество различных слов после лемматизации и удаления стоп-слов: {len(unique_lemmatized_filtered_words)}\")\n",
        "words_freq(lemmatized_filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsEnco6MPgEY",
        "outputId": "555f3a18-3ee3-43ec-90ac-9855a369b9e5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество слов после лемматизации и удаления стоп-слов: 100\n",
            "Количество различных слов после лемматизации и удаления стоп-слов: 51\n",
            "             Слово  Частота\n",
            "0            текст        6\n",
            "1        посчитать        2\n",
            "2       количество        2\n",
            "3        различный        3\n",
            "4            слово        4\n",
            "5                ,       11\n",
            "6    потребоваться        1\n",
            "7        выполнить        1\n",
            "8      токенизация        1\n",
            "9            любой        2\n",
            "10          способ        1\n",
            "11               .        8\n",
            "12           далее        1\n",
            "13    использовать        2\n",
            "14         готовый        1\n",
            "15        стеммера        1\n",
            "16    лемматизатор        1\n",
            "17      библиотека        1\n",
            "18      произвести        1\n",
            "19        удаление        3\n",
            "20     стопа-слово        3\n",
            "21            тест        1\n",
            "22          каждый        1\n",
            "23         процесс        2\n",
            "24           также        2\n",
            "25      комбинация        2\n",
            "26     субъективно        1\n",
            "27         оценить        2\n",
            "28      понятность        2\n",
            "29        стемминг        2\n",
            "30    лемматизация        2\n",
            "31        написать        1\n",
            "32             код        1\n",
            "33    векторизация        4\n",
            "34          размер        1\n",
            "35         словарь        2\n",
            "36         который        2\n",
            "37        выводить        1\n",
            "38       результат        1\n",
            "39     производить        1\n",
            "40        обратный        2\n",
            "41               —        1\n",
            "42        заменять        1\n",
            "43       численный        1\n",
            "44        значение        1\n",
            "45       прошедшее        1\n",
            "46  преобразование        1\n",
            "47     выполняться        2\n",
            "48      определить        1\n",
            "49     оптимальный        1\n",
            "50             ваш        1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_text = ' '.join(lemmatized_words)\n",
        "stemmed_text = ' '.join(stemmed_words)\n",
        "filtered_text = ' '.join(filtered_words)"
      ],
      "metadata": {
        "id": "Eb8OLHRzTyXR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Векторизация слов"
      ],
      "metadata": {
        "id": "PJgIHA5SHfDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_text(text, vocab_size):\n",
        "    vectorizer = CountVectorizer(max_features=vocab_size)\n",
        "    X = vectorizer.fit_transform([text])\n",
        "    return X, vectorizer\n",
        "\n",
        "def inverse_transform(X, vectorizer):\n",
        "    return vectorizer.inverse_transform(X)"
      ],
      "metadata": {
        "id": "WGIL2Ba7Dr9o"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# векторизации лематизированных слов\n",
        "X, vectorizer = vectorize_text(lemmatized_text, 70)\n",
        "print(\"Результат векторизации:\")\n",
        "print(X.toarray())\n",
        "\n",
        "inverse_text = inverse_transform(X, vectorizer)\n",
        "print(\"Обратное преобразование:\")\n",
        "print(inverse_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efLgyC9OUJ5m",
        "outputId": "f656df28-1033-4919-f498-2d9067c1ae2f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат векторизации:\n",
            "[[1 1 4 1 1 1 1 2 1 1 3 1 1 1 1 1 2 1 2 1 1 2 2 2 1 2 2 1 1 1 2 1 1 1 2 1\n",
            "  1 2 2 2 1 1 1 1 2 1 3 1 1 2 7 1 1 2 3 1 2 6 1 1 3 1 1]]\n",
            "Обратное преобразование:\n",
            "[array(['текст', 'посчитать', 'количество', 'различный', 'слово', 'для',\n",
            "       'что', 'потребоваться', 'выполнить', 'токенизация', 'по', 'любой',\n",
            "       'способ', 'далее', 'использовать', 'готовый', 'стеммера',\n",
            "       'лемматизатор', 'из', 'библиотека', 'произвести', 'удаление',\n",
            "       'стопа', 'тест', 'до', 'после', 'каждый', 'процесс', 'также',\n",
            "       'весь', 'они', 'комбинация', 'субъективно', 'оценить',\n",
            "       'понятность', 'стемминг', 'лемматизация', 'написать', 'код',\n",
            "       'векторизация', 'размер', 'словарь', 'который', 'выводить',\n",
            "       'результат', 'производить', 'обратный', 'заменять', 'всё',\n",
            "       'численный', 'значение', 'есть', 'на', 'прошедшее',\n",
            "       'преобразование', 'если', 'перед', 'выполняться', 'или', 'не',\n",
            "       'определить', 'оптимальный', 'ваш'], dtype='<U14')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# векторизации стемминговых слов\n",
        "X, vectorizer = vectorize_text(stemmed_text, 70)\n",
        "print(\"Результат векторизации:\")\n",
        "print(X.toarray())\n",
        "\n",
        "inverse_text = inverse_transform(X, vectorizer)\n",
        "print(\"Обратное преобразование:\")\n",
        "print(inverse_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxdKpR6tVM_3",
        "outputId": "ad801d98-fcc3-40ad-ea69-f2e0e7c17a04"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат векторизации:\n",
            "[[1 1 4 1 1 1 1 2 1 1 3 1 1 1 1 1 2 1 1 1 1 1 1 2 2 2 1 2 2 1 1 1 2 1 1 2\n",
            "  1 1 2 2 2 1 1 1 1 2 1 3 1 1 3 4 2 1 1 2 3 1 2 6 1 1 3 1 1]]\n",
            "Обратное преобразование:\n",
            "[array(['текст', 'посчита', 'количеств', 'различн', 'слов', 'для', 'чег',\n",
            "       'потреб', 'выполн', 'токенизац', 'по', 'люб', 'способ', 'дал',\n",
            "       'использова', 'готов', 'стеммер', 'лемматизатор', 'из',\n",
            "       'библиотек', 'произвест', 'удален', 'стоп', 'сл', 'тест', 'до',\n",
            "       'посл', 'кажд', 'процесс', 'такж', 'всех', 'их', 'комбинац',\n",
            "       'субъективн', 'оцен', 'понятн', 'стемминг', 'лемматизац', 'написа',\n",
            "       'код', 'векторизац', 'использу', 'размер', 'словар', 'котор',\n",
            "       'вывод', 'результат', 'производ', 'обратн', 'заменя', 'все',\n",
            "       'числен', 'значен', 'ест', 'на', 'прошедш', 'преобразован', 'есл',\n",
            "       'перед', 'выполня', 'ил', 'не', 'определ', 'оптимальн', 'ваш'],\n",
            "      dtype='<U12')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# векторизации отфильтрованных слов (после удаления стоп-слов)\n",
        "X, vectorizer = vectorize_text(filtered_text, 50)\n",
        "print(\"Результат векторизации:\")\n",
        "print(X.toarray())\n",
        "\n",
        "inverse_text = inverse_transform(X, vectorizer)\n",
        "print(\"Обратное преобразование:\")\n",
        "print(inverse_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui9n0Ae-VMh4",
        "outputId": "84822450-1fa2-43f2-a805-d6abd2c9fee5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат векторизации:\n",
            "[[1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1\n",
            "  1 1 1 1 1 1 2 5 1 1 3 2 5 2]]\n",
            "Обратное преобразование:\n",
            "[array(['посчитать', 'количество', 'различных', 'слов', 'потребуется',\n",
            "       'выполнить', 'словам', 'любым', 'далее', 'использовать', 'готовый',\n",
            "       'лемматизатор', 'любой', 'библиотеки', 'произвести', 'удаление',\n",
            "       'стоп', 'текста', 'каждого', 'процесса', 'также', 'комбинаций',\n",
            "       'оценить', 'понятность', 'лемматизации', 'написать', 'код',\n",
            "       'векторизации', 'используя', 'различный', 'который', 'выводит',\n",
            "       'производит', 'обратный', 'процесс', 'заменяет', 'значения',\n",
            "       'которые', 'слова', 'прошедшего', 'векторизацию', 'обратное',\n",
            "       'преобразование', 'векторизацией', 'выполнялись', 'лемматизация',\n",
            "       'определить', 'оптимальную', 'комбинацию', 'вашего'], dtype='<U14')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Оценка методов работы с текстом"
      ],
      "metadata": {
        "id": "6OVLAivTHi2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_text_understandability(text):\n",
        "    # Субъективная оценка понятности текста\n",
        "    print(f\"Текст: {text}\")\n",
        "    understandability = input(\"Оцените понятность текста (1-10): \")\n",
        "    return int(understandability)\n",
        "\n",
        "# Оценка понятности после стемминга\n",
        "print(\"Оценка понятности после стемминга:\")\n",
        "stemmed_score = evaluate_text_understandability(stemmed_text)\n",
        "\n",
        "# Оценка понятности после лемматизации\n",
        "print(\"Оценка понятности после лемматизации:\")\n",
        "lemmatized_score = evaluate_text_understandability(lemmatized_text)\n",
        "\n",
        "# Оценка понятности после удаления стоп-слов\n",
        "print(\"Оценка понятности после удаления стоп-слов:\")\n",
        "filtered_score = evaluate_text_understandability(filtered_text)\n",
        "\n",
        "# Оценка понятности после векторизации и обратного преобразования\n",
        "inverse_text_str = ' '.join([' '.join(words) for words in inverse_text])\n",
        "print(\"Оценка понятности после векторизации и обратного преобразования:\")\n",
        "inverse_score = evaluate_text_understandability(inverse_text_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "Iemnv9j-DuGg",
        "outputId": "24395dd9-bed6-40b3-f803-ac2b5365b792"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Оценка понятности после стемминга:\n",
            "Текст: в текст посчита количеств различн слов , для чег потреб выполн токенизац по слов люб способ . дал использова готов стеммер и лемматизатор из люб библиотек . произвест удален стоп-сл из текст . посчита количеств различн слов в тест до и посл кажд процесс , а такж всех их комбинац . субъективн оцен понятн текст посл стемминг , лемматизац и удален стоп-сл . написа код для векторизац текст , использу различн размер словар , котор вывод результат векторизац , а такж производ обратн процесс — заменя все числен значен , котор ест в словар , на слов . оцен понятн текст , прошедш векторизац и обратн преобразован , есл перед векторизац выполня ил не выполня стемминг , лемматизац и удален стоп-сл . определ оптимальн комбинац для ваш текст .\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-81689ba75026>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Оценка понятности после стемминга\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Оценка понятности после стемминга:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mstemmed_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_text_understandability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstemmed_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Оценка понятности после лемматизации\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-81689ba75026>\u001b[0m in \u001b[0;36mevaluate_text_understandability\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Субъективная оценка понятности текста\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Текст: {text}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0munderstandability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Оцените понятность текста (1-10): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munderstandability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}